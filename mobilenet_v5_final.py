# -*- coding: utf-8 -*-
"""MobileNet_V5_Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10KUKS4nP_xUnASMpkW4dBHM5URPUrX6V
"""

import os, random, shutil
import matplotlib.pyplot as plt
from collections import Counter
from torchvision import transforms
from torchvision.datasets import ImageFolder
from torchvision.utils import make_grid
from torch.utils.data import Subset, DataLoader
import numpy as np
import torch
from torch.utils.data import WeightedRandomSampler, DataLoader

#Paths
from google.colab import drive
drive.mount('/content/drive')

base_dir   = "/content/drive/MyDrive/Dataset/archive"
orig_train  = os.path.join(base_dir, "train")
orig_test   = os.path.join(base_dir, "test")

#Stage 10% sample on the VM
sample_ratio = 0.1
tmp_root="/content/tmp/fer2013_sample"
tmp_train = os.path.join(tmp_root, "train")
tmp_test = os.path.join(tmp_root, "test")

if os.path.exists(tmp_root):
    shutil.rmtree(tmp_root)

keep_classes = ['happy', 'neutral']

for src_dir, dst_dir in [(orig_train, tmp_train), (orig_test, tmp_test)]:
    os.makedirs(dst_dir, exist_ok=True)
    for label in os.listdir(src_dir):
        if label not in keep_classes:
            continue

        src_label = os.path.join(src_dir, label)
        if not os.path.isdir(src_label):
            continue

        dst_label = os.path.join(dst_dir, label)
        os.makedirs(dst_label, exist_ok=True)

        all_files = [
            f for f in os.listdir(src_label)
            if os.path.isfile(os.path.join(src_label, f))
        ]
        k = max(1, int(len(all_files) * sample_ratio))
        sample_files = random.sample(all_files, k)

        for fname in sample_files:
            shutil.copy(
                os.path.join(src_label, fname),
                os.path.join(dst_label, fname)
            )

    print(f"Copied 10% of '{src_dir}' ({keep_classes}) -> '{dst_dir}'")


#  Transform for MobileNetV2 (grayscale → 3-channel, resized, normalized)
transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=3),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

#Load Datasets
train_dataset = ImageFolder(tmp_train, transform=transform)
test_dataset  = ImageFolder(tmp_test, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)
test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False, num_workers=2)

print(f"Loaded {len(train_dataset)} train images")
print(f"Loaded {len(test_dataset)}  test images")

#Visualize class distribution in the TRAIN set
from collections import Counter
import matplotlib.pyplot as plt

train_counts = Counter(train_dataset.targets)
classes = train_dataset.classes

counts = [train_counts[i] for i in range(len(classes))]

plt.figure(figsize=(8,4))
plt.bar(classes, counts)
plt.xlabel("Emotion Class")
plt.ylabel("Number of Images")
plt.title("FER2013 10%‐Subset Train Class Distribution")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

import os
import random
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

#pretrained MobileNetV2
model = models.mobilenet_v2(pretrained=True)

#Fine-tuning
for param in model.features.parameters():
    param.requires_grad = False

num_ftrs = model.classifier[1].in_features
model.classifier[1] = nn.Linear(num_ftrs, len(train_dataset.classes))
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),
                       lr=1e-3)

from sklearn.metrics import classification_report
import torch

def evaluate_model():
    model.eval()
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for imgs, labels in test_loader:
            imgs, labels = imgs.to(device), labels.to(device)
            outputs = model(imgs)
            preds = outputs.argmax(dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    print("Classification Report:")
    print(classification_report(all_labels, all_preds, target_names=classes))

from torch.optim import Adam
from torch.optim.lr_scheduler import StepLR
import torch.nn.functional as F

optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3, weight_decay=1e-5)
scheduler = StepLR(optimizer, step_size=5, gamma=0.5)
criterion = nn.CrossEntropyLoss()

def train_epoch():
  model.train()
  total_loss, total_acc = 0, 0
  for imgs, labels in train_loader:
    imgs, labels = imgs.to(device), labels.to(device)
    optimizer.zero_grad()
    logits = model(imgs)
    loss = criterion(logits, labels)
    loss.backward()
    optimizer.step()
    preds = logits.argmax(dim=1)
    total_acc += (preds == labels).sum().item()
    total_loss += loss.item()*imgs.size(0)
  return total_loss / len(train_dataset), total_acc / len(train_dataset)

for epoch in range(1,20):
  train_loss, train_acc = train_epoch()
  scheduler.step()
  print(f"Epoch {epoch+1} - loss: {train_loss:.4f}, acc: {train_acc:.3f}")

evaluate_model()